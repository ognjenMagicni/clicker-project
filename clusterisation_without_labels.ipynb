{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lenovo/Desktop/Ognjen/ClickerProject/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pyannote.audio import Pipeline, Model, Inference\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import random\n",
    "import torch\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN, MeanShift\n",
    "from sklearn.metrics import rand_score, adjusted_mutual_info_score, silhouette_score, davies_bouldin_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "token = os.getenv(\"HUGGING_FACE_TOKEN\")\n",
    "directory  = \"audio_snimci\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_files_in_list(list_files: list, directory: str):\n",
    "  for f in os.listdir(directory):\n",
    "    if os.path.isfile(os.path.join(directory, f)):\n",
    "      list_files.append(os.path.join(directory, f))\n",
    "\n",
    "\n",
    "def function_heatmap(embedding: list):\n",
    "  \"\"\"speaker_1_list = []\n",
    "  for dir in list_dictionary:\n",
    "    insert_files_in_list(speaker_1_list,[],'a',dir)\"\"\"\n",
    "  n = len(embedding)\n",
    "  matrix = [[0]*n for _ in range(n)]\n",
    "  for i in range(n):\n",
    "    for j in range(n):\n",
    "      matrix[i][j] = cdist([embedding[i]],[embedding[j]],metric=\"cosine\")[0,0]\n",
    "  sns.heatmap(matrix)\n",
    "  return matrix\n",
    "def distribution(speaker_dictionaries,matrix):\n",
    "  previous_count = 0\n",
    "  cordinates_for_speaker = []\n",
    "  for speaker in speaker_dictionaries:\n",
    "    cordinates_for_speaker.append((previous_count,previous_count+len(os.listdir(speaker))))\n",
    "    previous_count+=len(os.listdir(speaker))\n",
    "  print(cordinates_for_speaker)\n",
    "  from_same_group = []\n",
    "  for speaker in cordinates_for_speaker:\n",
    "    l_cord = speaker[0]\n",
    "    r_cord = speaker[1]\n",
    "    for row in matrix[l_cord:r_cord]:\n",
    "      for e in row[l_cord:r_cord]:\n",
    "        from_same_group.append(e)\n",
    "\n",
    "  np_matrix = np.array(deepcopy(matrix))\n",
    "  for speaker in cordinates_for_speaker:\n",
    "    l_cord = speaker[0]\n",
    "    r_cord = speaker[1]\n",
    "    np_matrix[l_cord:r_cord,l_cord:r_cord] = 2\n",
    "  different_group = np_matrix.flatten()[np_matrix.flatten()!=2]\n",
    "\n",
    "  plt.hist(from_same_group,bins=20,color='green',alpha=0.5)\n",
    "  plt.hist(different_group,bins=10,color='red',alpha=0.5)\n",
    "  plt.show()\n",
    "\n",
    "def clusterisation_result(list_files_name: list, prediction: list):\n",
    "  p = {}\n",
    "  prediction_n = [ int(f) for f in prediction]\n",
    "  \n",
    "  for l in sorted(list(zip(list_files_name,prediction_n))):\n",
    "    if l[1] in p:\n",
    "      if not l[0] in p[l[1]]:\n",
    "        p[l[1]].append(l[0])\n",
    "    else:\n",
    "      p[l[1]] = []\n",
    "      p[l[1]].append(l[0])\n",
    "  for key, value in sorted(p.items()):\n",
    "      #print(f\"{key}: {[ v.split('/')[0] for v in value]}\")\n",
    "      print(f\"{key}: {[ v for v in value]}\")\n",
    "\n",
    "\n",
    "minimal_treshold = 0.4\n",
    "def calculate_threshold(i,embedding):\n",
    "  cosine_dist = sorted([ cdist([i],[j],metric='cosine')[0,0] for j in embedding])\n",
    "  difference = []\n",
    "  max_v = 0\n",
    "  index = 0\n",
    "  for i in range(1,len(cosine_dist)-1):\n",
    "    diff = cosine_dist[i+1]-cosine_dist[i]\n",
    "    difference.append(diff)\n",
    "    if diff>max_v and (cosine_dist[i]+cosine_dist[i+1])/2>minimal_treshold:\n",
    "      index = i\n",
    "      max_v = diff\n",
    "  treshold = (cosine_dist[index+1]+cosine_dist[index])/2\n",
    "  if treshold<0.8:\n",
    "    return treshold\n",
    "  return 0.8\n",
    "\n",
    "\n",
    "def my_algorithm_v2(list_files_new,embedding):\n",
    "  print(\"My algorithm\")\n",
    "  n = len(list_files_new)\n",
    "  prediction = [-1]*n\n",
    "  cluster=0\n",
    "  for i,audio_first in enumerate(embedding):\n",
    "    if prediction[i]>-1:\n",
    "      continue\n",
    "    treshold = calculate_threshold(audio_first,embedding)\n",
    "    for j,audio_second in enumerate(embedding):\n",
    "      if prediction[j]>-1:\n",
    "        continue\n",
    "      if cdist([audio_first],[audio_second],metric='cosine')[0,0]<treshold:\n",
    "        prediction[j] = cluster\n",
    "    cluster+=1\n",
    "\n",
    "  clusterisation_result(list_files_new, prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lenovo/Desktop/Ognjen/ClickerProject/venv/lib/python3.12/site-packages/pytorch_lightning/utilities/migration/migration.py:208: You have multiple `ModelCheckpoint` callback states in this checkpoint, but we found state keys that would end up colliding with each other after an upgrade, which means we can't differentiate which of your checkpoint callbacks needs which states. At least one of your `ModelCheckpoint` callbacks will not be able to reload the state.\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.5.1.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n",
      "/home/lenovo/Desktop/Ognjen/ClickerProject/venv/lib/python3.12/site-packages/pyannote/audio/core/model.py:692: UserWarning: Model has been trained with a task-dependent loss function. Set 'strict' to False to load the model without its loss function and prevent this warning from appearing. \n",
      "  warnings.warn(msg)\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.5.1.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.7.0+cu118. Bad things might happen unless you revert torch to 1.x.\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.7.0+cu118. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lenovo/Desktop/Ognjen/ClickerProject/venv/lib/python3.12/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['loss_func.W']\n"
     ]
    }
   ],
   "source": [
    "model = Model.from_pretrained(\"pyannote/embedding\",\n",
    "                              use_auth_token=token)\n",
    "inference = Inference(model, window=\"whole\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = []\n",
    "\n",
    "insert_files_in_list(list_files,directory)\n",
    "embedding = [inference(file) for file in list_files]\n",
    "combined = list(zip(list_files,embedding))\n",
    "random.shuffle(combined)\n",
    "\n",
    "list_files_new, embedding_new = zip(*combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My algorithm\n",
      "0: ['audio_snimci/1.wav', 'audio_snimci/3.wav']\n",
      "1: ['audio_snimci/2.wav', 'audio_snimci/4.wav']\n"
     ]
    }
   ],
   "source": [
    "my_algorithm_v2(list_files_new,embedding_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
